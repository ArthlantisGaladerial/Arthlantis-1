{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pMnvvUq2iEMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ce9fb7-34d5-4534-cf9e-977c8072c1a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "import openai\n",
        "import requests\n",
        "\n",
        "# Set up Streamlit app\n",
        "st.set_page_config(page_title=\"Arthlantis AI\", page_icon=\"ü§ñ\")\n",
        "st.title(\"Welcome to Arthlantis, I am AI Arthur! What can I help you with today? ü§ñ\")\n",
        "\n",
        "# Sidebar for settings\n",
        "st.sidebar.header(\"Settings\")\n",
        "\n",
        "# Custom model names for display\n",
        "model_display_names = {\n",
        "    \"Arthlantis 1\": \"gpt-3.5-turbo\",\n",
        "    \"Arthlantis 2\": \"gpt-4\"\n",
        "}\n",
        "\n",
        "# Model selection dropdown (users see custom names, backend uses real model names)\n",
        "selected_display_name = st.sidebar.selectbox(\"Choose AI Version:\", list(model_display_names.keys()), index=0)\n",
        "selected_model = model_display_names[selected_display_name]\n",
        "\n",
        "# Temperature slider\n",
        "temperature = st.sidebar.slider(\"Temperature:\", min_value=0.0, max_value=1.0, value=0.1, step=0.1)\n",
        "\n",
        "# Button to clear chat\n",
        "if st.sidebar.button(\"Clear Chat History\"):\n",
        "    st.session_state.messages = []\n",
        "    st.experimental_rerun()\n",
        "\n",
        "# File upload function\n",
        "def handle_file_upload():\n",
        "    uploaded_file = st.file_uploader(\"Upload a file\", type=[\"txt\", \"pdf\", \"docx\", \"csv\"])\n",
        "    if uploaded_file is not None:\n",
        "        if uploaded_file.type == \"text/plain\":\n",
        "            text = uploaded_file.read().decode(\"utf-8\")\n",
        "            st.text_area(\"File Content\", value=text, height=200)\n",
        "        elif uploaded_file.type == \"application/pdf\":\n",
        "            # Use PyPDF2 or pdfplumber to extract text\n",
        "            import PyPDF2\n",
        "            pdf_reader = PyPDF2.PdfReader(uploaded_file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "            st.text_area(\"PDF Content\", value=text, height=200)\n",
        "        elif uploaded_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "            from docx import Document\n",
        "            doc = Document(uploaded_file)\n",
        "            text = \"\"\n",
        "            for para in doc.paragraphs:\n",
        "                text += para.text\n",
        "            st.text_area(\"Docx Content\", value=text, height=200)\n",
        "        elif uploaded_file.type == \"text/csv\":\n",
        "            import pandas as pd\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "            st.write(df)\n",
        "            st.text_area(\"CSV Content\", value=df.to_string(), height=200)\n",
        "    return uploaded_file\n",
        "\n",
        "# Real-time web research functionality\n",
        "def web_search(query):\n",
        "    st.write(f\"Searching the web for: {query}\")\n",
        "    response = requests.get(f\"https://api.duckduckgo.com/?q={query}&format=json\")\n",
        "    if response.status_code == 200:\n",
        "        results = response.json()\n",
        "        try:\n",
        "            abstract = results.get(\"AbstractText\", \"No relevant information found.\")\n",
        "            st.write(abstract)\n",
        "        except KeyError:\n",
        "            st.write(\"Could not retrieve web data.\")\n",
        "    else:\n",
        "        st.write(\"Web search failed. Please try again.\")\n",
        "\n",
        "# StreamHandler for live updates\n",
        "class StreamHandler(BaseCallbackHandler):\n",
        "    def __init__(self, container, initial_text=\"\"):\n",
        "        self.container = container\n",
        "        self.text = initial_text\n",
        "\n",
        "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
        "        self.text += token\n",
        "        self.container.markdown(self.text)\n",
        "\n",
        "# Load ChatGPT with selected settings\n",
        "try:\n",
        "    chatgpt = ChatOpenAI(model_name=selected_model, temperature=temperature, streaming=True)\n",
        "except Exception as e:\n",
        "    st.error(f\"‚ö†Ô∏è Model Error: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# System prompt for assistant personality\n",
        "SYS_PROMPT = \"\"\"\n",
        "    Act as a helpful and humorous assistant. Be engaging, human-like, and ensure conversations are relaxed and enjoyable.\n",
        "\"\"\"\n",
        "\n",
        "# Create a prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", SYS_PROMPT),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# LLM chain\n",
        "llm_chain = prompt | chatgpt\n",
        "\n",
        "# Conversation history\n",
        "streamlit_msg_history = StreamlitChatMessageHistory()\n",
        "conversation_chain = RunnableWithMessageHistory(\n",
        "    llm_chain,\n",
        "    lambda session_id: streamlit_msg_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")\n",
        "\n",
        "# Display initial message\n",
        "if len(streamlit_msg_history.messages) == 0:\n",
        "    streamlit_msg_history.add_ai_message(\"How can I assist you today?\")\n",
        "\n",
        "# Render past messages\n",
        "for msg in streamlit_msg_history.messages:\n",
        "    st.chat_message(msg.type).write(msg.content)\n",
        "\n",
        "# Handle new user input\n",
        "if user_prompt := st.chat_input():\n",
        "    st.chat_message(\"human\").write(user_prompt)\n",
        "\n",
        "    if \"search\" in user_prompt.lower():\n",
        "        web_search(user_prompt)\n",
        "    else:\n",
        "        with st.chat_message(\"ai\"):\n",
        "            stream_handler = StreamHandler(st.empty())\n",
        "            config = {\"configurable\": {\"session_id\": \"any\"}, \"callbacks\": [stream_handler]}\n",
        "            response = conversation_chain.invoke({\"input\": user_prompt}, config)\n",
        "\n",
        "# File upload\n",
        "handle_file_upload()\n"
      ]
    }
  ]
}